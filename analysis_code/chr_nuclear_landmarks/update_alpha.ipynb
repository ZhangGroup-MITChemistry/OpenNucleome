{
  "metadata": {
    "language_info": {
      "name": ""
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport os\nimport subprocess\nimport sys\nimport copy\nimport MDAnalysis as mda",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "run_number                  = int(sys.argv[1]) #The current iteration index\nN_replicas                  = int(sys.argv[2]) #Numbers of individual simulations",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "update_chr_list             = np.array([i for i in range(1,23)])\n\nupdate_chr_list -= 1 #Update all the chromosomes except the sex chromosome\n\nncv                     = 30321\n\nstart_cv                = 0\nend_cv                  = 30321\nfirst_frames            = 500\n\nold_iter                = run_number-1",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\"\"\"Info files\"\"\"\ngLength             = np.loadtxt(\"gLengthFile.txt\",dtype=int)\nmaternalIdx         = np.loadtxt(\"maternalIdxFile.txt\",dtype=int)\npaternalIdx         = np.loadtxt(\"paternalIdxFile.txt\",dtype=int)\ndamid_data_low_res  = np.loadtxt(\"DamID-OE.txt\",usecols=[1])\ntsa_data_low_res    = np.loadtxt(\"TSA-Seq-OE.txt\",usecols=[1])\n\"\"\"End Info Files\"\"\"",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "### Average the individual simulations ###\nn_frames        = np.zeros(N_replicas)\nfor i in range(N_replicas):\n    traj_data   = mda.coordinates.LAMMPS.DCDReader(\"../../examples/HFF_100KB/DUMP_FILE.dcd\")\n    n_frames[i] = len(traj_data)-first_frames\n\ncvInd       = np.zeros((ncv, ), dtype=float)\ncvInd_tsa   = np.zeros((ncv, ), dtype=float)\nirun    = 0\nfor replica in range(1,N_replicas+1,1):\n    cvInd       += np.load(\"cvInd.txt_%d.npy\"%replica)\n    cvInd_tsa   += np.load(\"cvInd_tsa.txt_%d.npy\"%replica)\n    irun    += n_frames[replica-1]\ncvInd       /= irun\ncvInd_tsa   /= irun\nnp.savetxt('cvInd_iter%02d.txt'%(run_number), cvInd, fmt='%14.7e')\nnp.savetxt('cvInd_tsa_iter%02d.txt'%(run_number), cvInd_tsa, fmt='%14.7e')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "### Experimental constraint portion\n# Speckles and Lamina\ndamid_data_low_res_haploid  = np.zeros(30321)\ntsa_data_low_res_haploid    = np.zeros(30321)\nfor i in range(23):\n    damid_data_low_res_haploid[gLength[i]:gLength[i+1]] = 0.5*(damid_data_low_res[maternalIdx[i][0]-1:maternalIdx[i][1]] +\n                                                       damid_data_low_res[paternalIdx[i][0]-1:paternalIdx[i][1]]\n                                                       )\n    tsa_data_low_res_haploid[gLength[i]:gLength[i+1]] = 0.5*(tsa_data_low_res[maternalIdx[i][0]-1:maternalIdx[i][1]] +\n                                                       tsa_data_low_res[paternalIdx[i][0]-1:paternalIdx[i][1]]\n                                                       )\n\ngw_lamina                   =   np.mean(cvInd)\ngw_speckles                 =   np.mean(cvInd_tsa)\n\nexpt                        =   damid_data_low_res_haploid*gw_lamina #damid\nexpt_tsa                    =   tsa_data_low_res_haploid*gw_speckles #tsa-seq",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "## Start to do the Adam training (DamID)\n\nm_dw_dam                    = np.loadtxt('iter_num/%02d/mdw_dam.txt'%(run_number-1))\nv_dw_dam                    = np.loadtxt('iter_num/%02d/vdw_dam.txt'%(run_number-1))\nm_db_dam                    = np.loadtxt('iter_num/%02d/mdb_dam.txt'%(run_number-1))\nv_db_dam                    = np.loadtxt('iter_num/%02d/vdb_dam.txt'%(run_number-1))\nbeta1_dam                   = 0.9\nbeta2_dam                   = 0.999\nepsilon_dam                 = 1e-8\neta_dam                     = 0.01\nt_dam                       = int(np.loadtxt('t_dam.txt'%))\n\ngrad_dam        = -cvInd + expt\n# START TO DO THE ADAM TRAINING\n# momentum beta 1\n# *** weights *** #\nm_dw_dam        = beta1_dam*m_dw_dam + (1-beta1_dam)*grad_dam\n# *** biases *** #\nm_db_dam        = beta1_dam*m_db_dam + (1-beta1_dam)*grad_dam\n# rms beta 2\n# *** weights *** #\nv_dw_dam        = beta2_dam*v_dw_dam + (1-beta2_dam)*(grad_dam**2)\n# *** biases *** #\nv_db_dam        = beta2_dam*v_db_dam + (1-beta2_dam)*grad_dam\n\nsubprocess.call([\"mkdir -p iter_num/%02d\"%run_number],shell=True,stdout=subprocess.PIPE)\nnp.savetxt('iter_num/%02d/mdw_dam.txt'%(run_number), m_dw_dam.reshape((-1,1)), fmt='%15.12e')\nnp.savetxt('iter_num/%02d/vdw_dam.txt'%(run_number), v_dw_dam.reshape((-1,1)), fmt='%15.12e')\nnp.savetxt('iter_num/%02d/mdb_dam.txt'%(run_number), m_db_dam.reshape((-1,1)), fmt='%15.12e')\nnp.savetxt('iter_num/%02d/vdb_dam.txt'%(run_number), v_db_dam.reshape((-1,1)), fmt='%15.12e')\nnp.savetxt('iter_num/%02d/t_dam.txt'%(run_number), np.array([t_dam+1]).reshape((-1,1)), fmt='%d')\n\n## bias correction\nm_dw_corr_dam   = m_dw_dam/(1-beta1_dam**t_dam)\nm_db_corr_dam   = m_db_dam/(1-beta1_dam**t_dam)\nv_dw_corr_dam   = v_dw_dam/(1-beta2_dam**t_dam)\nv_db_corr_dam   = v_db_dam/(1-beta2_dam**t_dam)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "## Update the parameters (DamID)\n\ndalpha1_dam     = m_dw_corr_dam/(np.sqrt(v_dw_corr_dam)+epsilon_dam)\ndalpha2_dam     = m_db_corr_dam/(np.sqrt(v_db_corr_dam)+epsilon_dam)\n\ndamid = np.loadtxt(\"../../examples/HFF_100KB/potential/%02d/DamID.txt\"%(old_iter))\n\nfor i in update_chr_list:\n    damid[maternalIdx[i][0]-1:maternalIdx[i][1]] -= eta_dam*dalpha1_dam[gLength[i]:gLength[i+1]]\n    damid[paternalIdx[i][0]-1:paternalIdx[i][1]] -= eta_dam*dalpha1_dam[gLength[i]:gLength[i+1]]",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "## Start to do the Adam training (TSA-Seq)\n\nm_dw_tsa                    = np.loadtxt('iter_num/%02d/mdw_tsa.txt'%(run_number-1))\nv_dw_tsa                    = np.loadtxt('iter_num/%02d/vdw_tsa.txt'%(run_number-1))\nm_db_tsa                    = np.loadtxt('iter_num/%02d/mdb_tsa.txt'%(run_number-1))\nv_db_tsa                    = np.loadtxt('iter_num/%02d/vdb_tsa.txt'%(run_number-1))\nbeta1_tsa                   = 0.9\nbeta2_tsa                   = 0.999\nepsilon_tsa                 = 1e-8\neta_tsa                     = 0.01\nt_tsa                       = int(np.loadtxt('iter_num/%02d/t_tsa.txt'%(run_number-1)))\n\ngrad_tsa        = -cvInd_tsa + expt_tsa\n# START TO DO THE ADAM TRAINING\n# momentum beta 1\n# *** weights *** #\nm_dw_tsa        = beta1_tsa*m_dw_tsa + (1-beta1_tsa)*grad_tsa\n# *** biases *** #\nm_db_tsa        = beta1_tsa*m_db_tsa + (1-beta1_tsa)*grad_tsa\n# rms beta 2\n# *** weights *** #\nv_dw_tsa        = beta2_tsa*v_dw_tsa + (1-beta2_tsa)*(grad_tsa**2)\n# *** biases *** #\nv_db_tsa        = beta2_tsa*v_db_tsa + (1-beta2_tsa)*grad_tsa\n\nnp.savetxt('iter_num/%02d/mdw_tsa.txt'%(run_number), m_dw_tsa.reshape((-1,1)), fmt='%15.12e')\nnp.savetxt('iter_num/%02d/vdw_tsa.txt'%(run_number), v_dw_tsa.reshape((-1,1)), fmt='%15.12e')\nnp.savetxt('iter_num/%02d/mdb_tsa.txt'%(run_number), m_db_tsa.reshape((-1,1)), fmt='%15.12e')\nnp.savetxt('iter_num/%02d/vdb_tsa.txt'%(run_number), v_db_tsa.reshape((-1,1)), fmt='%15.12e')\nnp.savetxt('iter_num/%02d/t_tsa.txt'%(run_number), np.array([t_tsa+1]).reshape((-1,1)), fmt='%d')\n\n## bias correction\nm_dw_corr_tsa   = m_dw_tsa/(1-beta1_tsa**t_tsa)\nm_db_corr_tsa   = m_db_tsa/(1-beta1_tsa**t_tsa)\nv_dw_corr_tsa   = v_dw_tsa/(1-beta2_tsa**t_tsa)\nv_db_corr_tsa   = v_db_tsa/(1-beta2_tsa**t_tsa)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "## Update the parameters (TSA-Seq)\n\ndalpha1_tsa     = m_dw_corr_tsa/(np.sqrt(v_dw_corr_tsa)+epsilon_tsa)\ndalpha2_tsa     = m_db_corr_tsa/(np.sqrt(v_db_corr_tsa)+epsilon_tsa)\n\ntsaseq = np.loadtxt(\"../../examples/HFF_100KB/potential/%02d/TSA.txt\"%(old_iter))\n\nfor i in update_chr_list:\n    tsaseq[maternalIdx[i][0]-1:maternalIdx[i][1]] -= eta_tsa*dalpha1_tsa[gLength[i]:gLength[i+1]]\n    tsaseq[paternalIdx[i][0]-1:paternalIdx[i][1]] -= eta_tsa*dalpha1_tsa[gLength[i]:gLength[i+1]]",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#Added portion to overide the parameters to 0.0 if no expt signal on segment\nzero_signal_damid   = (damid_data_low_res[:]    == 0.0)\nzero_signal_tsa     = (tsa_data_low_res[:]      == 0.0)\ndamid[zero_signal_damid]  = 0.0\ntsaseq[zero_signal_tsa]    = 0.0\n\nsubprocess.call([\"mkdir -p ../../examples/HFF_100KB/potential/%02d/\"%(run_number)],shell=True,stdout=subprocess.PIPE)\nnp.savetxt(\"../../examples/HFF_100KB/potential/%02d/DamID.txt\"%(run_number),damid,fmt='%.6f')\nnp.savetxt(\"../../examples/HFF_100KB/potential/%02d/TSA.txt\"%(run_number),tsaseq,fmt='%.6f')\nnp.savetxt(\"../../examples/HFF_100KB/potential/%02d/TSA_8900.txt\"%(run_number),np.append(tsaseq,[0]*8900).reshape((-1,1)),fmt='%.6f')\nnp.savetxt(\"../../examples/HFF_100KB/potential/%02d/DamID_8900.txt\"%(run_number),np.append(damid,[0]*8900).reshape((-1,1)),fmt='%.6f')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}